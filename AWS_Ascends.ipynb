{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjhAwAK7uQR9m2OmUa7Ag5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BalajiMittapalli/Zelestra-Challenge/blob/main/AWS_Ascends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders optuna xgboost lightgbm catboost scikit-learn pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UCRo0r8n-SfC",
        "outputId": "d8be14b0-00a5-44a9-e1e3-ff8b252097ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaL1f0hZ9-S4",
        "outputId": "cc209be8-7abd-44bd-ffde-b7d753c7e827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Cell 1: Installs and Imports\n",
        "!pip install category_encoders optuna xgboost lightgbm catboost scikit-learn pandas numpy -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "\n",
        "# Suppress Optuna's specific warning about preferring `suggest_float` for `learning_rate`\n",
        "# and other common warnings to keep output cleaner during HPO.\n",
        "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning) # General user warnings often from libraries\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# For reproducibility in Optuna studies and KFold\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load Data\n",
        "df_train = pd.read_csv(\"/content/train.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "print(\"Train data shape:\", df_train.shape)\n",
        "print(\"Test data shape:\", df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8kW7byu-Xx0",
        "outputId": "e4417761-f6d8-4dc8-8d00-6f1969088942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (20000, 17)\n",
            "Test data shape: (12000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Separate Target & IDs, Initial Feature Lists\n",
        "y = df_train[\"efficiency\"].values\n",
        "X = df_train.drop([\"id\", \"efficiency\"], axis=1)\n",
        "X_test = df_test.drop([\"id\"], axis=1)\n",
        "test_ids = df_test[\"id\"].values\n",
        "\n",
        "# Original numerical features list (before engineering)\n",
        "original_numerical_feats = [\n",
        "    \"temperature\", \"irradiance\", \"humidity\", \"soiling_ratio\", \"voltage\",\n",
        "    \"current\", \"module_temperature\", \"cloud_coverage\", \"wind_speed\", \"pressure\",\n",
        "    \"panel_age\", \"maintenance_count\"\n",
        "]\n",
        "low_card_cat = [\"installation_type\"]\n",
        "high_card_cat = [\"string_id\", \"error_code\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UygwGTu4-gxN",
        "outputId": "ba79e080-44c5-4096-b389-78a22631ae45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (20000, 15)\n",
            "X_test shape: (12000, 15)\n",
            "y shape: (20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Coerce Numerical Features to Numeric Types\n",
        "# This step is crucial and should happen before feature engineering if engineered features depend on these.\n",
        "print(\"Coercing numerical features to numeric types...\")\n",
        "for df in (X, X_test):\n",
        "    # Check for non-numeric strings before coercion if necessary (for debugging)\n",
        "    # for col in original_numerical_feats:\n",
        "    #     if df[col].dtype == 'object':\n",
        "    #         non_numeric = df[col][~df[col].astype(str).str.match(r'^-?\\d+\\.?\\d*$')]\n",
        "    #         if not non_numeric.empty:\n",
        "    #             print(f\"Non-numeric values found in {col} before coerce: {non_numeric.unique()[:5]}\")\n",
        "    df[original_numerical_feats] = df[original_numerical_feats].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check NaNs introduced by coercion\n",
        "print(f\"NaNs in X after coercion: {X[original_numerical_feats].isnull().sum().sum()}\")\n",
        "print(f\"NaNs in X_test after coercion: {X_test[original_numerical_feats].isnull().sum().sum()}\")\n",
        "print(\"Coercion complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OISXCa3-lQr",
        "outputId": "d1a0dc21-23fe-4cb7-9f60-c7591bd6e023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coercing numerical features to numeric types...\n",
            "NaNs in X after coercion: 9375\n",
            "NaNs in X_test after coercion: 5538\n",
            "Coercion complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Feature Engineering\n",
        "print(\"Starting Feature Engineering...\")\n",
        "\n",
        "# (Keep existing features)\n",
        "for df in (X, X_test):\n",
        "    df['power_approx'] = df['voltage'] * df['current']\n",
        "    df['temp_delta'] = df['module_temperature'] - df['temperature']\n",
        "\n",
        "    # New Features:\n",
        "    # Interactions with panel_age\n",
        "    df['soiling_impact_aged'] = df['soiling_ratio'] * (df['panel_age'] + 1) # Interaction\n",
        "    df['maintenance_per_year'] = df['maintenance_count'] / (df['panel_age'] + 1e-6) # Ratio, avoid div by zero\n",
        "\n",
        "    # Environmental interactions\n",
        "    df['irradiance_cloud_effect'] = df['irradiance'] * (1 - df['cloud_coverage']/100) # Effective irradiance\n",
        "    df['temp_rise_potential'] = df['irradiance'] / (df['wind_speed'] + 1e-6) # Irradiance vs cooling\n",
        "\n",
        "    # Polynomial features for key variables (simple quadratics)\n",
        "    for col in ['temperature', 'irradiance', 'module_temperature']:\n",
        "        df[col + '_sq'] = df[col]**2\n",
        "\n",
        "    # Age and maintenance interaction\n",
        "    df['age_x_maintenance'] = df['panel_age'] * df['maintenance_count']\n",
        "\n",
        "    # Humidity and temperature\n",
        "    df['humidity_temp_interaction'] = df['humidity'] * df['temperature']\n",
        "\n",
        "print(\"Feature Engineering Complete.\")\n",
        "\n",
        "# Check for new NaNs from division by zero or other ops\n",
        "print(f\"NaNs in X after new FE: {X.isnull().sum().sum()}\")\n",
        "print(f\"NaNs in X_test after new FE: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# Make sure to update numerical_feats list in Cell 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIa5TUXv-nvE",
        "outputId": "997f1dc3-3493-4f29-ad55-8e97d1e700c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Feature Engineering...\n",
            "Feature Engineering Complete.\n",
            "NaNs in X after FE (power_approx): 1925\n",
            "NaNs in X_test after FE (temp_delta): 1134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Updated Feature Lists (Post-Engineering)\n",
        "\n",
        "# Keep your original ones\n",
        "original_numerical_feats_from_cell3 = [\n",
        "    \"temperature\", \"irradiance\", \"humidity\", \"soiling_ratio\", \"voltage\",\n",
        "    \"current\", \"module_temperature\", \"cloud_coverage\", \"wind_speed\", \"pressure\",\n",
        "    \"panel_age\", \"maintenance_count\"\n",
        "]\n",
        "\n",
        "# Add the new engineered features to the list\n",
        "engineered_numerical_feats = [\n",
        "    'power_approx', 'temp_delta',\n",
        "    'soiling_impact_aged', 'maintenance_per_year',\n",
        "    'irradiance_cloud_effect', 'temp_rise_potential',\n",
        "    'temperature_sq', 'irradiance_sq', 'module_temperature_sq',\n",
        "    'age_x_maintenance', 'humidity_temp_interaction'\n",
        "]\n",
        "\n",
        "numerical_feats = original_numerical_feats_from_cell3 + engineered_numerical_feats\n",
        "\n",
        "# Ensure all new features are actually present in X, X_test\n",
        "for df_check in [X, X_test]:\n",
        "    for f in numerical_feats:\n",
        "        if f not in df_check.columns:\n",
        "            print(f\"WARNING: Feature {f} not found in DataFrame columns after FE!\")\n",
        "\n",
        "\n",
        "print(\"Final numerical features:\", numerical_feats)\n",
        "# The rest of Cell 6 (the loop for df in (X,X_test) where features are created)\n",
        "# should be MOVED to Cell 5 as shown above. Cell 6 should now primarily be for defining the list."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tyMIKCZ-p1c",
        "outputId": "6e24a0e0-b589-420e-8be0-76f451a4bad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final numerical features: ['temperature', 'irradiance', 'humidity', 'soiling_ratio', 'voltage', 'current', 'module_temperature', 'cloud_coverage', 'wind_speed', 'pressure', 'panel_age', 'maintenance_count', 'power_approx', 'temp_delta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Preprocessing Pipelines Definition\n",
        "\n",
        "# Numerical pipeline with imputation and scaling\n",
        "num_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy='median')), # Median is robust to outliers\n",
        "    (\"scale\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Low cardinality categorical pipeline with imputation and OneHotEncoding\n",
        "cat_low_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy='most_frequent')),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # sparse_output=False for easier downstream use if needed\n",
        "])\n",
        "\n",
        "# High cardinality categorical pipeline with imputation and TargetEncoding\n",
        "cat_high_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy='constant', fill_value='_MISSING_CAT_')), # Explicitly handle NaNs before TE\n",
        "    (\"target_enc\", TargetEncoder(min_samples_leaf=50, smoothing=20, handle_unknown='value', handle_missing='value'))\n",
        "    # Consider cols parameter if not all high_card_cat are suitable for TE\n",
        "])\n",
        "\n",
        "# Combined preprocessor\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", num_pipe, numerical_feats),\n",
        "    (\"cat_low\", cat_low_pipe, low_card_cat),\n",
        "    (\"cat_high\", cat_high_pipe, high_card_cat),\n",
        "], remainder='drop', n_jobs=-1) # remainder='passthrough' if you have other cols you want to keep\n",
        "\n",
        "print(\"Preprocessor defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69U9k0ZR-sLG",
        "outputId": "1d22b29e-fb0a-48e3-dea5-328cef733dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessor defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: LightGBM Optuna Objective and Optimization\n",
        "def objective_lgb(trial, X_data, y_data):\n",
        "    params = {\n",
        "        'objective': 'regression_l1', # MAE objective, often robust\n",
        "        'metric': 'rmse', # Still optimize for RMSE\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'n_estimators': 1500,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
        "    }\n",
        "    model = Pipeline([\n",
        "        ('prep', preprocessor),\n",
        "        ('lgbm', LGBMRegressor(**params, verbosity=-1)) # verbosity=-1 to suppress LGBM training output\n",
        "    ])\n",
        "    cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE) # Reduced splits for faster HPO if needed\n",
        "    # Using n_jobs=2 for cross_val_score to limit parallelism during Optuna if main loop is also parallel\n",
        "    scores = cross_val_score(model, X_data, y_data, cv=cv,\n",
        "                             scoring='neg_root_mean_squared_error', n_jobs=2)\n",
        "    return -np.mean(scores)\n",
        "\n",
        "print(\"Optimizing LightGBM...\")\n",
        "study_lgb = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
        "study_lgb.optimize(lambda trial: objective_lgb(trial, X, y), n_trials=75, n_jobs=1) # n_jobs=1 for Optuna to avoid oversubscribing CPUs if CV has n_jobs\n",
        "best_lgb_params = study_lgb.best_params\n",
        "print(\"Best LightGBM CV RMSE:\", study_lgb.best_value)\n",
        "print(\"Best LightGBM parameters:\", best_lgb_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh4xpgyE-unO",
        "outputId": "d5a60c17-4010-486a-ad70-1454a9f3ec37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 10:41:22,272] A new study created in memory with name: no-name-cc5f72ec-5d57-4fea-a116-4e837c29c31f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing LightGBM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 10:41:49,935] Trial 0 finished with value: 0.1036918465391868 and parameters: {'learning_rate': 0.015355286838886862, 'num_leaves': 287, 'max_depth': 10, 'min_child_samples': 62, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'bagging_freq': 1, 'lambda_l1': 0.6245760287469893, 'lambda_l2': 0.002570603566117598}. Best is trial 0 with value: 0.1036918465391868.\n",
            "[I 2025-06-07 10:42:06,486] Trial 1 finished with value: 0.10383732687205402 and parameters: {'learning_rate': 0.04170553216181044, 'num_leaves': 25, 'max_depth': 12, 'min_child_samples': 84, 'feature_fraction': 0.6061695553391381, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 2, 'lambda_l1': 5.472429642032198e-06, 'lambda_l2': 0.00052821153945323}. Best is trial 0 with value: 0.1036918465391868.\n",
            "[I 2025-06-07 10:42:38,001] Trial 2 finished with value: 0.10361918407348605 and parameters: {'learning_rate': 0.018236581424556055, 'num_leaves': 101, 'max_depth': 9, 'min_child_samples': 18, 'feature_fraction': 0.6460723242676091, 'bagging_fraction': 0.6831809216468459, 'bagging_freq': 4, 'lambda_l1': 0.1165691561324743, 'lambda_l2': 6.267062696005991e-07}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:42:46,628] Trial 3 finished with value: 0.1036973657094001 and parameters: {'learning_rate': 0.023334818836184625, 'num_leaves': 186, 'max_depth': 3, 'min_child_samples': 63, 'feature_fraction': 0.5852620618436457, 'bagging_fraction': 0.5325257964926398, 'bagging_freq': 7, 'lambda_l1': 4.905556676028774, 'lambda_l2': 0.18861495878553936}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:43:05,910] Trial 4 finished with value: 0.10362706501258127 and parameters: {'learning_rate': 0.012453219846912198, 'num_leaves': 47, 'max_depth': 9, 'min_child_samples': 47, 'feature_fraction': 0.5610191174223894, 'bagging_fraction': 0.7475884550556351, 'bagging_freq': 1, 'lambda_l1': 1.527156759251193, 'lambda_l2': 2.133142332373004e-06}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:43:30,417] Trial 5 finished with value: 0.10374337458128027 and parameters: {'learning_rate': 0.036385753170854684, 'num_leaves': 107, 'max_depth': 8, 'min_child_samples': 57, 'feature_fraction': 0.5924272277627636, 'bagging_fraction': 0.9847923138822793, 'bagging_freq': 6, 'lambda_l1': 2.854239907497756, 'lambda_l2': 1.1309571585271483}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:43:38,803] Trial 6 finished with value: 0.1036523076159768 and parameters: {'learning_rate': 0.0299816694120633, 'num_leaves': 279, 'max_depth': 3, 'min_child_samples': 23, 'feature_fraction': 0.522613644455269, 'bagging_fraction': 0.6626651653816322, 'bagging_freq': 3, 'lambda_l1': 2.7678419414850017e-06, 'lambda_l2': 0.28749982347407854}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:44:08,026] Trial 7 finished with value: 0.10374050733896896 and parameters: {'learning_rate': 0.014558505116213708, 'num_leaves': 98, 'max_depth': 8, 'min_child_samples': 18, 'feature_fraction': 0.9010984903770198, 'bagging_fraction': 0.5372753218398854, 'bagging_freq': 7, 'lambda_l1': 0.08916674715636537, 'lambda_l2': 6.143857495033091e-07}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:44:37,953] Trial 8 finished with value: 0.10366105035682367 and parameters: {'learning_rate': 0.0050834018700114374, 'num_leaves': 249, 'max_depth': 10, 'min_child_samples': 74, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'bagging_freq': 3, 'lambda_l1': 1.1036250149900698e-07, 'lambda_l2': 0.5860448217200517}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:44:47,175] Trial 9 finished with value: 0.10364902347284763 and parameters: {'learning_rate': 0.03235188302117385, 'num_leaves': 112, 'max_depth': 3, 'min_child_samples': 34, 'feature_fraction': 0.6625916610133735, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 5, 'lambda_l1': 0.9658611176861268, 'lambda_l2': 0.0001778010520878397}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:45:06,174] Trial 10 finished with value: 0.10392517381439767 and parameters: {'learning_rate': 0.08484397325237236, 'num_leaves': 178, 'max_depth': 6, 'min_child_samples': 6, 'feature_fraction': 0.751265608837398, 'bagging_fraction': 0.7606165441675251, 'bagging_freq': 4, 'lambda_l1': 0.004137630881036838, 'lambda_l2': 2.2864821825098135e-08}. Best is trial 2 with value: 0.10361918407348605.\n",
            "[I 2025-06-07 10:45:22,637] Trial 11 finished with value: 0.1035724442040878 and parameters: {'learning_rate': 0.008478760087719483, 'num_leaves': 23, 'max_depth': 6, 'min_child_samples': 41, 'feature_fraction': 0.7171781358782056, 'bagging_fraction': 0.7409481648316648, 'bagging_freq': 1, 'lambda_l1': 0.0029151336209232927, 'lambda_l2': 2.9195814354420653e-06}. Best is trial 11 with value: 0.1035724442040878.\n",
            "[I 2025-06-07 10:45:42,692] Trial 12 finished with value: 0.10359574324894158 and parameters: {'learning_rate': 0.007387436944029744, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 38, 'feature_fraction': 0.7542782371321683, 'bagging_fraction': 0.7127679105159319, 'bagging_freq': 4, 'lambda_l1': 0.0021839487437881376, 'lambda_l2': 4.79292853707996e-06}. Best is trial 11 with value: 0.1035724442040878.\n",
            "[I 2025-06-07 10:46:04,950] Trial 13 finished with value: 0.10361660820840016 and parameters: {'learning_rate': 0.0067143864037574824, 'num_leaves': 59, 'max_depth': 6, 'min_child_samples': 44, 'feature_fraction': 0.7668054281678611, 'bagging_fraction': 0.833931982285774, 'bagging_freq': 2, 'lambda_l1': 0.0004956691645620256, 'lambda_l2': 2.8687872507869527e-05}. Best is trial 11 with value: 0.1035724442040878.\n",
            "[I 2025-06-07 10:46:20,421] Trial 14 finished with value: 0.10359928149743354 and parameters: {'learning_rate': 0.008778212178558932, 'num_leaves': 23, 'max_depth': 5, 'min_child_samples': 100, 'feature_fraction': 0.8155421717694825, 'bagging_fraction': 0.8085506759518797, 'bagging_freq': 5, 'lambda_l1': 0.0027876190934883935, 'lambda_l2': 4.089844254345068e-08}. Best is trial 11 with value: 0.1035724442040878.\n",
            "[I 2025-06-07 10:46:36,009] Trial 15 finished with value: 0.10358633923997469 and parameters: {'learning_rate': 0.008264332862154052, 'num_leaves': 74, 'max_depth': 5, 'min_child_samples': 35, 'feature_fraction': 0.6934641371803111, 'bagging_fraction': 0.6808586372525282, 'bagging_freq': 2, 'lambda_l1': 3.156615285733687e-05, 'lambda_l2': 7.284319435498869e-06}. Best is trial 11 with value: 0.1035724442040878.\n",
            "[I 2025-06-07 10:46:50,941] Trial 16 finished with value: 0.10357193330632464 and parameters: {'learning_rate': 0.010768024916395167, 'num_leaves': 142, 'max_depth': 5, 'min_child_samples': 30, 'feature_fraction': 0.6810422728033312, 'bagging_fraction': 0.6272672891085348, 'bagging_freq': 2, 'lambda_l1': 2.7952651140818567e-05, 'lambda_l2': 0.009972883683414422}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:47:05,191] Trial 17 finished with value: 0.10359122950438697 and parameters: {'learning_rate': 0.010848674581144958, 'num_leaves': 147, 'max_depth': 5, 'min_child_samples': 27, 'feature_fraction': 0.8448372126058836, 'bagging_fraction': 0.6219596844331323, 'bagging_freq': 1, 'lambda_l1': 2.1219899323605756e-08, 'lambda_l2': 0.010993417108982753}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:47:39,562] Trial 18 finished with value: 0.10375147702380146 and parameters: {'learning_rate': 0.0052908132214173, 'num_leaves': 224, 'max_depth': 7, 'min_child_samples': 5, 'feature_fraction': 0.6895298790285849, 'bagging_fraction': 0.9134336554829188, 'bagging_freq': 3, 'lambda_l1': 3.929361276753199e-05, 'lambda_l2': 0.011061825427555402}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:47:51,704] Trial 19 finished with value: 0.10362192878383088 and parameters: {'learning_rate': 0.010508845483925076, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 50, 'feature_fraction': 0.7985061943499071, 'bagging_fraction': 0.6338135758919312, 'bagging_freq': 2, 'lambda_l1': 3.359183778987816e-07, 'lambda_l2': 4.695918344827544}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:48:12,489] Trial 20 finished with value: 0.10385808303347696 and parameters: {'learning_rate': 0.057994166292221545, 'num_leaves': 236, 'max_depth': 7, 'min_child_samples': 74, 'feature_fraction': 0.9811976457592746, 'bagging_fraction': 0.7647547408281348, 'bagging_freq': 1, 'lambda_l1': 0.00013015851195897221, 'lambda_l2': 0.00010413311631145382}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:48:28,375] Trial 21 finished with value: 0.10359564400076435 and parameters: {'learning_rate': 0.007745007174972361, 'num_leaves': 78, 'max_depth': 5, 'min_child_samples': 34, 'feature_fraction': 0.7033157549700315, 'bagging_fraction': 0.7098975040881204, 'bagging_freq': 2, 'lambda_l1': 8.31819570043442e-06, 'lambda_l2': 5.71476447931604e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:48:40,522] Trial 22 finished with value: 0.1035891056492424 and parameters: {'learning_rate': 0.009476786058357096, 'num_leaves': 131, 'max_depth': 4, 'min_child_samples': 41, 'feature_fraction': 0.7072892016158608, 'bagging_fraction': 0.6616703820622021, 'bagging_freq': 2, 'lambda_l1': 0.022410115647054113, 'lambda_l2': 1.5470861364979506e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:48:52,760] Trial 23 finished with value: 0.10363712696649201 and parameters: {'learning_rate': 0.006691862717516499, 'num_leaves': 77, 'max_depth': 4, 'min_child_samples': 27, 'feature_fraction': 0.6280357197472805, 'bagging_fraction': 0.7191744474730926, 'bagging_freq': 3, 'lambda_l1': 6.951206089320071e-05, 'lambda_l2': 3.542503552548869e-05}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:49:09,286] Trial 24 finished with value: 0.1036240465966223 and parameters: {'learning_rate': 0.019969249482584925, 'num_leaves': 41, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.7173977827786409, 'bagging_fraction': 0.604193135697043, 'bagging_freq': 1, 'lambda_l1': 0.00038967176159458657, 'lambda_l2': 0.0016289899804704253}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:49:23,199] Trial 25 finished with value: 0.10362575314995728 and parameters: {'learning_rate': 0.01343205253483405, 'num_leaves': 180, 'max_depth': 5, 'min_child_samples': 30, 'feature_fraction': 0.6755258726941459, 'bagging_fraction': 0.5017436395895467, 'bagging_freq': 2, 'lambda_l1': 1.0737613044186844e-06, 'lambda_l2': 0.032710532931123165}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:49:48,265] Trial 26 finished with value: 0.10360555005704389 and parameters: {'learning_rate': 0.006189821360733718, 'num_leaves': 76, 'max_depth': 7, 'min_child_samples': 55, 'feature_fraction': 0.7278675571091091, 'bagging_fraction': 0.7787588257864038, 'bagging_freq': 3, 'lambda_l1': 3.338406325738405e-05, 'lambda_l2': 2.116934420527076e-05}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:49:58,550] Trial 27 finished with value: 0.10362637946861027 and parameters: {'learning_rate': 0.008770410350818452, 'num_leaves': 126, 'max_depth': 4, 'min_child_samples': 39, 'feature_fraction': 0.5015757619351703, 'bagging_fraction': 0.6735408602410227, 'bagging_freq': 1, 'lambda_l1': 1.671228780760669e-05, 'lambda_l2': 0.0007803671793888274}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:50:14,686] Trial 28 finished with value: 0.10358484429333599 and parameters: {'learning_rate': 0.01105837552325989, 'num_leaves': 211, 'max_depth': 5, 'min_child_samples': 19, 'feature_fraction': 0.7923316828616863, 'bagging_fraction': 0.6323585999023394, 'bagging_freq': 2, 'lambda_l1': 0.011447995139099864, 'lambda_l2': 2.0375955652743375e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:50:33,477] Trial 29 finished with value: 0.1036458841463725 and parameters: {'learning_rate': 0.017669712985004866, 'num_leaves': 200, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.7921118649442972, 'bagging_fraction': 0.5642717219431337, 'bagging_freq': 1, 'lambda_l1': 0.0487001357276134, 'lambda_l2': 1.1659515266835437e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:50:57,396] Trial 30 finished with value: 0.10365230641099366 and parameters: {'learning_rate': 0.012159971507811599, 'num_leaves': 291, 'max_depth': 7, 'min_child_samples': 23, 'feature_fraction': 0.8442508401830646, 'bagging_fraction': 0.6461929012683579, 'bagging_freq': 1, 'lambda_l1': 0.011292341195434912, 'lambda_l2': 9.116475220081749e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:51:15,690] Trial 31 finished with value: 0.10357673233144264 and parameters: {'learning_rate': 0.0102774032210115, 'num_leaves': 208, 'max_depth': 5, 'min_child_samples': 33, 'feature_fraction': 0.6430338068008336, 'bagging_fraction': 0.6953396298334026, 'bagging_freq': 2, 'lambda_l1': 0.0004526216759404876, 'lambda_l2': 3.6434239218638053e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:52:12,306] Trial 32 finished with value: 0.10369177971612238 and parameters: {'learning_rate': 0.015406672229432747, 'num_leaves': 208, 'max_depth': 12, 'min_child_samples': 30, 'feature_fraction': 0.6279989329959174, 'bagging_fraction': 0.6019615142781028, 'bagging_freq': 2, 'lambda_l1': 0.0010699317833543884, 'lambda_l2': 4.857789463458924e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:52:26,015] Trial 33 finished with value: 0.10359127603300303 and parameters: {'learning_rate': 0.011004617109632376, 'num_leaves': 262, 'max_depth': 4, 'min_child_samples': 19, 'feature_fraction': 0.6499000639889603, 'bagging_fraction': 0.5760929151563963, 'bagging_freq': 3, 'lambda_l1': 0.2870122568536504, 'lambda_l2': 2.0176459741494413e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:52:39,992] Trial 34 finished with value: 0.10367129347146442 and parameters: {'learning_rate': 0.02277503943744231, 'num_leaves': 212, 'max_depth': 5, 'min_child_samples': 45, 'feature_fraction': 0.548411554685583, 'bagging_fraction': 0.729337212701245, 'bagging_freq': 2, 'lambda_l1': 0.007309563560462441, 'lambda_l2': 2.6802298827759393e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:52:58,143] Trial 35 finished with value: 0.10362875420784759 and parameters: {'learning_rate': 0.016321155684212024, 'num_leaves': 164, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.7326957072288297, 'bagging_fraction': 0.6975562781145817, 'bagging_freq': 1, 'lambda_l1': 0.00021136038607612385, 'lambda_l2': 3.8811101624424124e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:53:40,836] Trial 36 finished with value: 0.10374276704753908 and parameters: {'learning_rate': 0.012633030700867768, 'num_leaves': 236, 'max_depth': 10, 'min_child_samples': 23, 'feature_fraction': 0.6142580264099177, 'bagging_fraction': 0.7955779763911461, 'bagging_freq': 2, 'lambda_l1': 0.0009623602157213103, 'lambda_l2': 1.2531360972931326e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:53:50,060] Trial 37 finished with value: 0.10369147373254033 and parameters: {'learning_rate': 0.027409264250200512, 'num_leaves': 194, 'max_depth': 3, 'min_child_samples': 61, 'feature_fraction': 0.5745108979587996, 'bagging_fraction': 0.7373020692334828, 'bagging_freq': 3, 'lambda_l1': 0.3915330318151553, 'lambda_l2': 6.020414173127034e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:54:27,190] Trial 38 finished with value: 0.10360990804378463 and parameters: {'learning_rate': 0.00597975936784399, 'num_leaves': 162, 'max_depth': 11, 'min_child_samples': 53, 'feature_fraction': 0.777440636066043, 'bagging_fraction': 0.6361613401834281, 'bagging_freq': 4, 'lambda_l1': 0.01191405600133519, 'lambda_l2': 0.0378476773488831}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:54:50,881] Trial 39 finished with value: 0.10367805514230181 and parameters: {'learning_rate': 0.02036496093434185, 'num_leaves': 269, 'max_depth': 8, 'min_child_samples': 31, 'feature_fraction': 0.6614655419305004, 'bagging_fraction': 0.6944550261875324, 'bagging_freq': 1, 'lambda_l1': 0.04152974886424352, 'lambda_l2': 1.0345540848947746e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:55:04,956] Trial 40 finished with value: 0.10365635633497565 and parameters: {'learning_rate': 0.01036192756082338, 'num_leaves': 223, 'max_depth': 5, 'min_child_samples': 67, 'feature_fraction': 0.8227832724007171, 'bagging_fraction': 0.5626951758542896, 'bagging_freq': 5, 'lambda_l1': 5.323957303964649e-06, 'lambda_l2': 0.005035847212281081}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:55:20,548] Trial 41 finished with value: 0.10358985215402783 and parameters: {'learning_rate': 0.008053070283555721, 'num_leaves': 35, 'max_depth': 5, 'min_child_samples': 37, 'feature_fraction': 0.6851340945673315, 'bagging_fraction': 0.6608583747057708, 'bagging_freq': 2, 'lambda_l1': 0.000199366287371199, 'lambda_l2': 5.970542148035886e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:55:34,176] Trial 42 finished with value: 0.1035986160572561 and parameters: {'learning_rate': 0.00896743205328047, 'num_leaves': 87, 'max_depth': 4, 'min_child_samples': 46, 'feature_fraction': 0.7332761900704389, 'bagging_fraction': 0.6812730473825839, 'bagging_freq': 2, 'lambda_l1': 0.0011535358278474475, 'lambda_l2': 7.11304300812711e-05}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:55:51,266] Trial 43 finished with value: 0.10362541434325256 and parameters: {'learning_rate': 0.014471696778592504, 'num_leaves': 57, 'max_depth': 6, 'min_child_samples': 26, 'feature_fraction': 0.5948137019113914, 'bagging_fraction': 0.6107677553519384, 'bagging_freq': 2, 'lambda_l1': 7.590682522171988e-05, 'lambda_l2': 0.000431360745133564}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:56:05,657] Trial 44 finished with value: 0.10359206253172046 and parameters: {'learning_rate': 0.007599641290180711, 'num_leaves': 33, 'max_depth': 5, 'min_child_samples': 33, 'feature_fraction': 0.6354728081409541, 'bagging_fraction': 0.7515326762355697, 'bagging_freq': 1, 'lambda_l1': 1.3793212526175915e-06, 'lambda_l2': 1.2023476532289076e-05}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:56:14,128] Trial 45 finished with value: 0.1036600067843562 and parameters: {'learning_rate': 0.009928334952806199, 'num_leaves': 112, 'max_depth': 3, 'min_child_samples': 42, 'feature_fraction': 0.6732398161295569, 'bagging_fraction': 0.645903559189803, 'bagging_freq': 3, 'lambda_l1': 2.113465555967829e-05, 'lambda_l2': 2.0808492796576726e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:56:33,672] Trial 46 finished with value: 0.10361270429673208 and parameters: {'learning_rate': 0.011456430870754113, 'num_leaves': 248, 'max_depth': 6, 'min_child_samples': 19, 'feature_fraction': 0.7441775375264296, 'bagging_fraction': 0.5868582418662421, 'bagging_freq': 2, 'lambda_l1': 0.0004894102217587967, 'lambda_l2': 2.424666735642281e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:56:58,076] Trial 47 finished with value: 0.10362466319459211 and parameters: {'learning_rate': 0.005773453148164925, 'num_leaves': 173, 'max_depth': 7, 'min_child_samples': 50, 'feature_fraction': 0.6916463748997976, 'bagging_fraction': 0.6897498478508747, 'bagging_freq': 6, 'lambda_l1': 0.0035278702284399343, 'lambda_l2': 0.13955808223214855}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:57:33,644] Trial 48 finished with value: 0.10359829937611797 and parameters: {'learning_rate': 0.0068981174235951985, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 37, 'feature_fraction': 0.7643983752466357, 'bagging_fraction': 0.8383844334559684, 'bagging_freq': 3, 'lambda_l1': 0.11303110274859196, 'lambda_l2': 2.494583184068875e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:57:51,389] Trial 49 finished with value: 0.10361066254791951 and parameters: {'learning_rate': 0.00840383474324305, 'num_leaves': 22, 'max_depth': 5, 'min_child_samples': 9, 'feature_fraction': 0.8932453914900429, 'bagging_fraction': 0.9480450770644245, 'bagging_freq': 4, 'lambda_l1': 9.452465902144047e-06, 'lambda_l2': 1.0590342371535348e-05}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:58:02,399] Trial 50 finished with value: 0.10358320333096327 and parameters: {'learning_rate': 0.013499031575142364, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 17, 'feature_fraction': 0.8658928840700139, 'bagging_fraction': 0.6275382184700257, 'bagging_freq': 1, 'lambda_l1': 7.069633956227869e-05, 'lambda_l2': 9.38335836692355e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:58:13,920] Trial 51 finished with value: 0.10357887863867148 and parameters: {'learning_rate': 0.012381586637282215, 'num_leaves': 140, 'max_depth': 4, 'min_child_samples': 17, 'feature_fraction': 0.9231467239144024, 'bagging_fraction': 0.6230567860015361, 'bagging_freq': 1, 'lambda_l1': 9.530702210855992e-05, 'lambda_l2': 1.2740952441697648e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:58:22,744] Trial 52 finished with value: 0.10361623689282969 and parameters: {'learning_rate': 0.01298460287500786, 'num_leaves': 152, 'max_depth': 3, 'min_child_samples': 22, 'feature_fraction': 0.9352669958194593, 'bagging_fraction': 0.6127729811860648, 'bagging_freq': 1, 'lambda_l1': 0.00012330022813739866, 'lambda_l2': 7.625012421350776e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:58:34,449] Trial 53 finished with value: 0.10360242057850792 and parameters: {'learning_rate': 0.014356729459953853, 'num_leaves': 128, 'max_depth': 4, 'min_child_samples': 16, 'feature_fraction': 0.9246276415797241, 'bagging_fraction': 0.6216992132380322, 'bagging_freq': 1, 'lambda_l1': 0.001411700494907469, 'lambda_l2': 1.4598321286555273e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:58:46,457] Trial 54 finished with value: 0.10359868518782318 and parameters: {'learning_rate': 0.017165349287525816, 'num_leaves': 193, 'max_depth': 4, 'min_child_samples': 11, 'feature_fraction': 0.8673031740974743, 'bagging_fraction': 0.6501166465180832, 'bagging_freq': 1, 'lambda_l1': 6.664266705329585e-05, 'lambda_l2': 1.8395948847649485e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:58:55,046] Trial 55 finished with value: 0.10363074323980506 and parameters: {'learning_rate': 0.009542831572041936, 'num_leaves': 143, 'max_depth': 3, 'min_child_samples': 9, 'feature_fraction': 0.9697468990132135, 'bagging_fraction': 0.5365045309289982, 'bagging_freq': 1, 'lambda_l1': 0.000497486043083427, 'lambda_l2': 6.700518914863293e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:59:06,463] Trial 56 finished with value: 0.10358524803893962 and parameters: {'learning_rate': 0.011661020360330164, 'num_leaves': 122, 'max_depth': 4, 'min_child_samples': 26, 'feature_fraction': 0.9086189265594987, 'bagging_fraction': 0.5849732307457277, 'bagging_freq': 1, 'lambda_l1': 0.005376385926348999, 'lambda_l2': 3.132785599174916e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:59:26,652] Trial 57 finished with value: 0.1036552695188139 and parameters: {'learning_rate': 0.019783157538701645, 'num_leaves': 185, 'max_depth': 6, 'min_child_samples': 17, 'feature_fraction': 0.8620368248109758, 'bagging_fraction': 0.6315169329293273, 'bagging_freq': 2, 'lambda_l1': 0.0022418873480490424, 'lambda_l2': 2.4593335642856835e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:59:41,193] Trial 58 finished with value: 0.10362660775595153 and parameters: {'learning_rate': 0.025871478228758637, 'num_leaves': 172, 'max_depth': 5, 'min_child_samples': 21, 'feature_fraction': 0.945153784688608, 'bagging_fraction': 0.708184237555929, 'bagging_freq': 1, 'lambda_l1': 3.989526900385157e-06, 'lambda_l2': 3.617478770908891e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 10:59:52,908] Trial 59 finished with value: 0.10373860997860737 and parameters: {'learning_rate': 0.04262657700404133, 'num_leaves': 152, 'max_depth': 4, 'min_child_samples': 100, 'feature_fraction': 0.8125154892168508, 'bagging_fraction': 0.6664070244112075, 'bagging_freq': 2, 'lambda_l1': 0.00024751262619885907, 'lambda_l2': 7.427174371378646e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:00:08,158] Trial 60 finished with value: 0.10361549862762753 and parameters: {'learning_rate': 0.014048091629926755, 'num_leaves': 139, 'max_depth': 5, 'min_child_samples': 29, 'feature_fraction': 0.9992682327877371, 'bagging_fraction': 0.5618875745693719, 'bagging_freq': 1, 'lambda_l1': 1.9243341960130705e-06, 'lambda_l2': 2.0346298031969705}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:00:19,397] Trial 61 finished with value: 0.10357993362134879 and parameters: {'learning_rate': 0.010262513102607515, 'num_leaves': 119, 'max_depth': 4, 'min_child_samples': 25, 'feature_fraction': 0.9111263140759065, 'bagging_fraction': 0.5831610543684786, 'bagging_freq': 1, 'lambda_l1': 0.007655712356587584, 'lambda_l2': 2.841647096428674e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:00:30,759] Trial 62 finished with value: 0.10360120348902342 and parameters: {'learning_rate': 0.009891425755086652, 'num_leaves': 115, 'max_depth': 4, 'min_child_samples': 24, 'feature_fraction': 0.8769279308555519, 'bagging_fraction': 0.591564171328944, 'bagging_freq': 1, 'lambda_l1': 0.0194446838697466, 'lambda_l2': 8.2757186908039e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:00:39,722] Trial 63 finished with value: 0.1036162147584054 and parameters: {'learning_rate': 0.011737721694289818, 'num_leaves': 157, 'max_depth': 3, 'min_child_samples': 16, 'feature_fraction': 0.9566191833745118, 'bagging_fraction': 0.6543102301272428, 'bagging_freq': 1, 'lambda_l1': 1.3890885518999122e-05, 'lambda_l2': 0.0001963795807280145}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:00:54,420] Trial 64 finished with value: 0.1041376343702631 and parameters: {'learning_rate': 0.09896717178096956, 'num_leaves': 136, 'max_depth': 5, 'min_child_samples': 33, 'feature_fraction': 0.9230805426270339, 'bagging_fraction': 0.503171802896324, 'bagging_freq': 2, 'lambda_l1': 0.0007670233803707332, 'lambda_l2': 4.475368173674566e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:01:05,324] Trial 65 finished with value: 0.10360508816734955 and parameters: {'learning_rate': 0.015887387784541858, 'num_leaves': 300, 'max_depth': 4, 'min_child_samples': 40, 'feature_fraction': 0.9011987933881489, 'bagging_fraction': 0.5455259669339134, 'bagging_freq': 1, 'lambda_l1': 4.825850514094944e-05, 'lambda_l2': 1.52047939409882e-06}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:01:20,690] Trial 66 finished with value: 0.10360559581978501 and parameters: {'learning_rate': 0.009045330356735323, 'num_leaves': 99, 'max_depth': 5, 'min_child_samples': 7, 'feature_fraction': 0.7152631272242053, 'bagging_fraction': 0.6245751772129815, 'bagging_freq': 7, 'lambda_l1': 0.0001428577604882615, 'lambda_l2': 1.835104162465352e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:01:35,005] Trial 67 finished with value: 0.10360758382394405 and parameters: {'learning_rate': 0.0071075677440520435, 'num_leaves': 218, 'max_depth': 4, 'min_child_samples': 20, 'feature_fraction': 0.840076507764517, 'bagging_fraction': 0.7743109127756179, 'bagging_freq': 2, 'lambda_l1': 0.030594715993416087, 'lambda_l2': 1.2862127332372802e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:01:53,073] Trial 68 finished with value: 0.10362601747454847 and parameters: {'learning_rate': 0.010824033920272676, 'num_leaves': 169, 'max_depth': 6, 'min_child_samples': 28, 'feature_fraction': 0.9142747433392563, 'bagging_fraction': 0.5211658699266125, 'bagging_freq': 1, 'lambda_l1': 0.008878417269417908, 'lambda_l2': 4.445337755826246e-08}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:02:02,001] Trial 69 finished with value: 0.10361734940942713 and parameters: {'learning_rate': 0.01299078588240103, 'num_leaves': 202, 'max_depth': 3, 'min_child_samples': 25, 'feature_fraction': 0.793369116520829, 'bagging_fraction': 0.6069474983913663, 'bagging_freq': 2, 'lambda_l1': 4.886469486676231e-07, 'lambda_l2': 1.191028723151636e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:02:14,907] Trial 70 finished with value: 0.10366576123376539 and parameters: {'learning_rate': 0.008385093366483557, 'num_leaves': 107, 'max_depth': 5, 'min_child_samples': 96, 'feature_fraction': 0.6554933979818997, 'bagging_fraction': 0.6722636142999849, 'bagging_freq': 1, 'lambda_l1': 0.064161047663261, 'lambda_l2': 0.001005989733102363}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:02:26,022] Trial 71 finished with value: 0.10359824481000066 and parameters: {'learning_rate': 0.011986173695109074, 'num_leaves': 120, 'max_depth': 4, 'min_child_samples': 25, 'feature_fraction': 0.8995925596343409, 'bagging_fraction': 0.5750060368093348, 'bagging_freq': 1, 'lambda_l1': 0.00497849268186954, 'lambda_l2': 2.761693299385477e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:02:37,266] Trial 72 finished with value: 0.10357710880828615 and parameters: {'learning_rate': 0.010330797692582576, 'num_leaves': 128, 'max_depth': 4, 'min_child_samples': 31, 'feature_fraction': 0.8840692047565957, 'bagging_fraction': 0.5950865200790736, 'bagging_freq': 1, 'lambda_l1': 0.0020040705048092805, 'lambda_l2': 3.3144554065954664e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:02:48,169] Trial 73 finished with value: 0.10360135840748189 and parameters: {'learning_rate': 0.010395962327668117, 'num_leaves': 154, 'max_depth': 4, 'min_child_samples': 36, 'feature_fraction': 0.8598343437547425, 'bagging_fraction': 0.5528696312262508, 'bagging_freq': 1, 'lambda_l1': 0.01394001714086173, 'lambda_l2': 6.86080188067528e-07}. Best is trial 16 with value: 0.10357193330632464.\n",
            "[I 2025-06-07 11:03:04,010] Trial 74 finished with value: 0.1035827763981751 and parameters: {'learning_rate': 0.009407353932513404, 'num_leaves': 132, 'max_depth': 5, 'min_child_samples': 31, 'feature_fraction': 0.8758050371376058, 'bagging_fraction': 0.599492714469866, 'bagging_freq': 2, 'lambda_l1': 0.0017991288632109416, 'lambda_l2': 1.1059090191136749e-06}. Best is trial 16 with value: 0.10357193330632464.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best LightGBM CV RMSE: 0.10357193330632464\n",
            "Best LightGBM parameters: {'learning_rate': 0.010768024916395167, 'num_leaves': 142, 'max_depth': 5, 'min_child_samples': 30, 'feature_fraction': 0.6810422728033312, 'bagging_fraction': 0.6272672891085348, 'bagging_freq': 2, 'lambda_l1': 2.7952651140818567e-05, 'lambda_l2': 0.009972883683414422}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8.1: Save Best LightGBM Parameters to JSON\n",
        "import json\n",
        "\n",
        "# Ensure best_lgb_params is defined from the previous Optuna cell\n",
        "if 'best_lgb_params' in locals() and best_lgb_params:\n",
        "    lgb_params_filename = \"best_lgb_params.json\"\n",
        "    with open(lgb_params_filename, 'w') as f:\n",
        "        json.dump(best_lgb_params, f, indent=4) # indent=4 makes the JSON file human-readable\n",
        "    print(f\"Best LightGBM parameters saved to {lgb_params_filename}\")\n",
        "\n",
        "    # To verify, you can load it back (optional)\n",
        "    # with open(lgb_params_filename, 'r') as f:\n",
        "    #     loaded_params = json.load(f)\n",
        "    # print(\"Loaded params for verification:\", loaded_params)\n",
        "else:\n",
        "    print(\"Error: 'best_lgb_params' not found or is empty. Please run the LightGBM optimization cell first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkdyWIOTFYyR",
        "outputId": "e0206e1e-bac4-41d6-aad3-e4ecb72a3b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best LightGBM parameters saved to best_lgb_params.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: CatBoost Optuna Objective and Optimization (Minimally Changed for Speed - Recommended Iterations)\n",
        "def objective_cat(trial, X_data, y_data):\n",
        "    params = {\n",
        "        'loss_function': 'RMSE',\n",
        "        'iterations': 300,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True), # Adjusted for fewer iterations\n",
        "        'depth': trial.suggest_int('depth', 4, 12), # You can keep this range\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10.0, log=True),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
        "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
        "        'random_seed': RANDOM_STATE,\n",
        "        'thread_count': 2\n",
        "    }\n",
        "    if params['bootstrap_type'] == 'MVS':\n",
        "        params['subsample'] = trial.suggest_float('subsample_mvs', 0.1, 1.0)\n",
        "    elif params['bootstrap_type'] == 'Bernoulli':\n",
        "         params['subsample'] = trial.suggest_float('subsample_bernoulli', 0.1, 1.0)\n",
        "\n",
        "    model = Pipeline([\n",
        "        ('prep', preprocessor),\n",
        "        ('cat', CatBoostRegressor(**params, verbose=0))\n",
        "    ])\n",
        "    cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "    scores = cross_val_score(model, X_data, y_data, cv=cv,\n",
        "                             scoring='neg_root_mean_squared_error', n_jobs=2)\n",
        "    return -np.mean(scores)\n",
        "\n",
        "print(\"Optimizing CatBoost (Recommended 'minimum best' iterations for HPO speed)...\")\n",
        "study_cat = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
        "study_cat.optimize(lambda trial: objective_cat(trial, X, y), n_trials=50, n_jobs=1) # Kept n_trials=50\n",
        "best_cat_params = study_cat.best_params\n",
        "print(\"Best CatBoost CV RMSE (from faster HPO):\", study_cat.best_value)\n",
        "print(\"Best CatBoost parameters (from faster HPO):\", best_cat_params)\n",
        "\n",
        "# REMEMBER: For the final model in Cell 11, INCREASE 'iterations' significantly\n",
        "# (e.g., back to 1500, 2000, or even more based on best_cat_params).\n",
        "# Example for Cell 11:\n",
        "# final_cat_params = best_cat_params.copy()\n",
        "# final_cat_params['iterations'] = 2000 # Use a larger number for the final model\n",
        "# # Ensure the learning rate found by Optuna is appropriate or adjust if needed for more iterations.\n",
        "# # Sometimes, if HPO used a higher LR due to fewer iterations, you might want to slightly\n",
        "# # decrease the LR for the final model with many more iterations.\n",
        "# # However, often the Optuna-found LR works well enough.\n",
        "# ... rest of final_cat_params update ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STBF-yUdT0nu",
        "outputId": "a4552464-be0a-432c-a448-b5fb2088cb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-07 12:13:28,151] A new study created in memory with name: no-name-7db1c9b3-f550-4611-8260-468f0e58748c\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing CatBoost (Recommended 'minimum best' iterations for HPO speed)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 12:15:23,971] Trial 0 finished with value: 0.10418672957920339 and parameters: {'learning_rate': 0.030710573677773714, 'depth': 12, 'l2_leaf_reg': 1.5702970884055387, 'border_count': 166, 'bootstrap_type': 'Bayesian', 'grow_policy': 'SymmetricTree'}. Best is trial 0 with value: 0.10418672957920339.\n",
            "[I 2025-06-07 12:16:24,904] Trial 1 finished with value: 0.10475437627144443 and parameters: {'learning_rate': 0.010636066512540286, 'depth': 12, 'l2_leaf_reg': 3.142880890840109, 'border_count': 79, 'bootstrap_type': 'MVS', 'grow_policy': 'SymmetricTree', 'subsample_mvs': 0.6506676052501416}. Best is trial 0 with value: 0.10418672957920339.\n",
            "[I 2025-06-07 12:16:42,626] Trial 2 finished with value: 0.10337334150998294 and parameters: {'learning_rate': 0.01518747922672247, 'depth': 6, 'l2_leaf_reg': 0.1256277350380703, 'border_count': 134, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Lossguide'}. Best is trial 2 with value: 0.10337334150998294.\n",
            "[I 2025-06-07 12:16:47,862] Trial 3 finished with value: 0.10350303374979886 and parameters: {'learning_rate': 0.016666983286066417, 'depth': 4, 'l2_leaf_reg': 7.025166339242156, 'border_count': 248, 'bootstrap_type': 'Bayesian', 'grow_policy': 'SymmetricTree'}. Best is trial 2 with value: 0.10337334150998294.\n",
            "[I 2025-06-07 12:16:58,112] Trial 4 finished with value: 0.10294495045906604 and parameters: {'learning_rate': 0.04407984038169244, 'depth': 4, 'l2_leaf_reg': 5.345166110646819, 'border_count': 89, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:17:19,369] Trial 5 finished with value: 0.10400794648859324 and parameters: {'learning_rate': 0.10196967939171485, 'depth': 12, 'l2_leaf_reg': 4.83595277646595, 'border_count': 165, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:19:31,274] Trial 6 finished with value: 0.10425120144698748 and parameters: {'learning_rate': 0.022544116997360492, 'depth': 11, 'l2_leaf_reg': 0.11756010900231852, 'border_count': 94, 'bootstrap_type': 'MVS', 'grow_policy': 'Depthwise', 'subsample_mvs': 0.2788441133807552}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:24:24,231] Trial 7 finished with value: 0.10407126892998017 and parameters: {'learning_rate': 0.010166803740022877, 'depth': 11, 'l2_leaf_reg': 1.3199942261535018, 'border_count': 195, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:24:34,598] Trial 8 finished with value: 0.10299435461141475 and parameters: {'learning_rate': 0.026946865572417687, 'depth': 4, 'l2_leaf_reg': 0.08569331925053984, 'border_count': 104, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.7847065437552077}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:27:10,533] Trial 9 finished with value: 0.10518507850190248 and parameters: {'learning_rate': 0.05373267600451109, 'depth': 10, 'l2_leaf_reg': 0.30296104428212484, 'border_count': 149, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:27:18,881] Trial 10 finished with value: 0.10562798498679034 and parameters: {'learning_rate': 0.1696879465047447, 'depth': 7, 'l2_leaf_reg': 0.010535179945522732, 'border_count': 36, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Lossguide', 'subsample_bernoulli': 0.12464910007665059}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:27:29,780] Trial 11 finished with value: 0.10327384958059464 and parameters: {'learning_rate': 0.047936135580135174, 'depth': 4, 'l2_leaf_reg': 0.023804491906597426, 'border_count': 94, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.990244137859479}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:27:43,011] Trial 12 finished with value: 0.10461312627815729 and parameters: {'learning_rate': 0.08259235291455887, 'depth': 5, 'l2_leaf_reg': 0.5246539331338612, 'border_count': 48, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Lossguide', 'subsample_bernoulli': 0.9519127109303397}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:28:01,381] Trial 13 finished with value: 0.1033460841037308 and parameters: {'learning_rate': 0.02816812451825095, 'depth': 8, 'l2_leaf_reg': 0.06110553776422125, 'border_count': 115, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.8035759028446494}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:28:13,725] Trial 14 finished with value: 0.10351963751883231 and parameters: {'learning_rate': 0.04065007167440147, 'depth': 6, 'l2_leaf_reg': 0.49329877620561213, 'border_count': 62, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.3810114423299047}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:28:27,851] Trial 15 finished with value: 0.10435500520055116 and parameters: {'learning_rate': 0.06898263855987757, 'depth': 8, 'l2_leaf_reg': 0.04374345244799966, 'border_count': 105, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Lossguide', 'subsample_bernoulli': 0.5065651342396101}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:28:40,150] Trial 16 finished with value: 0.10316838001009007 and parameters: {'learning_rate': 0.03468935799273656, 'depth': 5, 'l2_leaf_reg': 0.22749871012549103, 'border_count': 73, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.6081765206086109}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:28:48,272] Trial 17 finished with value: 0.10316018876733704 and parameters: {'learning_rate': 0.02099870089997876, 'depth': 4, 'l2_leaf_reg': 1.2829803843549814, 'border_count': 120, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.11882220983506347}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:28:55,940] Trial 18 finished with value: 0.10427398462621747 and parameters: {'learning_rate': 0.12367040189667017, 'depth': 6, 'l2_leaf_reg': 0.02013682101778743, 'border_count': 200, 'bootstrap_type': 'Bayesian', 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:30:09,730] Trial 19 finished with value: 0.10417566651784824 and parameters: {'learning_rate': 0.06231356467019049, 'depth': 9, 'l2_leaf_reg': 9.088203500057283, 'border_count': 133, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'subsample_bernoulli': 0.9972439475103052}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:30:24,100] Trial 20 finished with value: 0.1030483653743075 and parameters: {'learning_rate': 0.023021055397080215, 'depth': 5, 'l2_leaf_reg': 0.11961165468407801, 'border_count': 64, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.8665379925501621}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:30:38,602] Trial 21 finished with value: 0.10314210571031535 and parameters: {'learning_rate': 0.026848889409978836, 'depth': 5, 'l2_leaf_reg': 0.10085596708112878, 'border_count': 62, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.9084684401370251}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:30:48,790] Trial 22 finished with value: 0.10301401723007864 and parameters: {'learning_rate': 0.03765408060593434, 'depth': 4, 'l2_leaf_reg': 0.188416748937958, 'border_count': 83, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.7570595121117654}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:30:59,110] Trial 23 finished with value: 0.10301125798998287 and parameters: {'learning_rate': 0.03879675965001791, 'depth': 4, 'l2_leaf_reg': 0.6054148764003378, 'border_count': 93, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.7282869760048611}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:31:14,190] Trial 24 finished with value: 0.10345607938941315 and parameters: {'learning_rate': 0.045037850161290756, 'depth': 7, 'l2_leaf_reg': 0.7532553273800618, 'border_count': 102, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.4869771030247198}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:31:24,515] Trial 25 finished with value: 0.10327702299069311 and parameters: {'learning_rate': 0.056927391885526535, 'depth': 4, 'l2_leaf_reg': 2.8679471456269234, 'border_count': 37, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:31:39,500] Trial 26 finished with value: 0.10318848733366112 and parameters: {'learning_rate': 0.016250099263264702, 'depth': 5, 'l2_leaf_reg': 0.0524921564100531, 'border_count': 120, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.698400548896568}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:31:54,645] Trial 27 finished with value: 0.10407440550006856 and parameters: {'learning_rate': 0.07558367711899786, 'depth': 7, 'l2_leaf_reg': 2.0812479192277635, 'border_count': 85, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'subsample_mvs': 0.5308021461468453}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:31:59,466] Trial 28 finished with value: 0.10311744753589754 and parameters: {'learning_rate': 0.03463006213961952, 'depth': 6, 'l2_leaf_reg': 0.9159542458690022, 'border_count': 147, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'subsample_bernoulli': 0.1631721739341378}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:32:09,603] Trial 29 finished with value: 0.10295026875854019 and parameters: {'learning_rate': 0.031126697663243726, 'depth': 4, 'l2_leaf_reg': 0.43032254851492757, 'border_count': 168, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:32:24,498] Trial 30 finished with value: 0.10299534703260076 and parameters: {'learning_rate': 0.029502376750985194, 'depth': 5, 'l2_leaf_reg': 0.028788219168588765, 'border_count': 182, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:32:40,447] Trial 31 finished with value: 0.10305923915325306 and parameters: {'learning_rate': 0.02898293869634324, 'depth': 5, 'l2_leaf_reg': 0.02848277314516373, 'border_count': 193, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:32:50,187] Trial 32 finished with value: 0.10317964742151123 and parameters: {'learning_rate': 0.018606518363284384, 'depth': 4, 'l2_leaf_reg': 0.011912030201239193, 'border_count': 171, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:33:05,906] Trial 33 finished with value: 0.10356234756505171 and parameters: {'learning_rate': 0.012450879296899255, 'depth': 5, 'l2_leaf_reg': 0.07336854474435645, 'border_count': 214, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:33:23,942] Trial 34 finished with value: 0.10325339247934129 and parameters: {'learning_rate': 0.026020902202352456, 'depth': 6, 'l2_leaf_reg': 0.037201095630331034, 'border_count': 158, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:33:33,657] Trial 35 finished with value: 0.10296018792435431 and parameters: {'learning_rate': 0.032246602856128175, 'depth': 4, 'l2_leaf_reg': 0.017236491478721135, 'border_count': 222, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:33:39,432] Trial 36 finished with value: 0.10397786565507235 and parameters: {'learning_rate': 0.01327446750792522, 'depth': 4, 'l2_leaf_reg': 5.858998541125543, 'border_count': 241, 'bootstrap_type': 'Bayesian', 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:33:49,868] Trial 37 finished with value: 0.1031480842571764 and parameters: {'learning_rate': 0.01935722622109423, 'depth': 4, 'l2_leaf_reg': 0.01581243924581151, 'border_count': 224, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.10294495045906604.\n",
            "[I 2025-06-07 12:34:00,222] Trial 38 finished with value: 0.10293242871156993 and parameters: {'learning_rate': 0.048185961512502734, 'depth': 4, 'l2_leaf_reg': 3.923124608133838, 'border_count': 231, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 38 with value: 0.10293242871156993.\n",
            "[I 2025-06-07 12:34:25,370] Trial 39 finished with value: 0.10323447452970433 and parameters: {'learning_rate': 0.0510370405476993, 'depth': 6, 'l2_leaf_reg': 3.7658859289045936, 'border_count': 255, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 38 with value: 0.10293242871156993.\n",
            "[I 2025-06-07 12:37:58,722] Trial 40 finished with value: 0.10553540232893868 and parameters: {'learning_rate': 0.09141790444997704, 'depth': 10, 'l2_leaf_reg': 1.9772569273195202, 'border_count': 231, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 38 with value: 0.10293242871156993.\n",
            "[I 2025-06-07 12:38:08,682] Trial 41 finished with value: 0.10290275692191271 and parameters: {'learning_rate': 0.032838940051137355, 'depth': 4, 'l2_leaf_reg': 8.722287511624351, 'border_count': 214, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 41 with value: 0.10290275692191271.\n",
            "[I 2025-06-07 12:38:18,509] Trial 42 finished with value: 0.10289498361813935 and parameters: {'learning_rate': 0.033012966807138715, 'depth': 4, 'l2_leaf_reg': 8.361927793592796, 'border_count': 208, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.10289498361813935.\n",
            "[I 2025-06-07 12:38:32,008] Trial 43 finished with value: 0.10293578718341687 and parameters: {'learning_rate': 0.043215979178542446, 'depth': 5, 'l2_leaf_reg': 9.631568533565098, 'border_count': 209, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.10289498361813935.\n",
            "[I 2025-06-07 12:38:45,844] Trial 44 finished with value: 0.10294824554952435 and parameters: {'learning_rate': 0.04391566926192112, 'depth': 5, 'l2_leaf_reg': 8.39653156766501, 'border_count': 206, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.10289498361813935.\n",
            "[I 2025-06-07 12:38:55,792] Trial 45 finished with value: 0.10300977555576214 and parameters: {'learning_rate': 0.05633326807885257, 'depth': 4, 'l2_leaf_reg': 4.664388694874308, 'border_count': 235, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.10289498361813935.\n",
            "[I 2025-06-07 12:39:09,250] Trial 46 finished with value: 0.10301909299221801 and parameters: {'learning_rate': 0.0432988543799909, 'depth': 5, 'l2_leaf_reg': 5.722751088620985, 'border_count': 189, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.10289498361813935.\n",
            "[I 2025-06-07 12:39:19,205] Trial 47 finished with value: 0.10302840170534341 and parameters: {'learning_rate': 0.06793273215095813, 'depth': 4, 'l2_leaf_reg': 9.622631948817476, 'border_count': 213, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.10289498361813935.\n",
            "[I 2025-06-07 12:39:42,946] Trial 48 finished with value: 0.10340957600278913 and parameters: {'learning_rate': 0.0519552282587139, 'depth': 6, 'l2_leaf_reg': 3.1261703020069427, 'border_count': 243, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.10289498361813935.\n",
            "[I 2025-06-07 12:39:49,780] Trial 49 finished with value: 0.10298236797268309 and parameters: {'learning_rate': 0.0234854652226986, 'depth': 5, 'l2_leaf_reg': 6.653516718938138, 'border_count': 205, 'bootstrap_type': 'Bayesian', 'grow_policy': 'SymmetricTree'}. Best is trial 42 with value: 0.10289498361813935.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CatBoost CV RMSE (from faster HPO): 0.10289498361813935\n",
            "Best CatBoost parameters (from faster HPO): {'learning_rate': 0.033012966807138715, 'depth': 4, 'l2_leaf_reg': 8.361927793592796, 'border_count': 208, 'bootstrap_type': 'Bayesian', 'grow_policy': 'Depthwise'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json # Ensure json module is imported\n",
        "\n",
        "filename_cat_params = \"best_catboost_hpo_params.json\" # Define the filename\n",
        "try:\n",
        "    with open(filename_cat_params, 'w') as f:\n",
        "        json.dump(best_cat_params, f, indent=4) # Save only the best_cat_params dictionary\n",
        "    print(f\"Successfully saved Best CatBoost parameters to {filename_cat_params}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving CatBoost parameters to JSON: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJugWQF7ZhUh",
        "outputId": "144d61b7-3813-4944-d8d0-8769a5b36987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved Best CatBoost parameters to best_catboost_hpo_params.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: XGBoost Optuna Objective and Optimization (Minimally Changed for Speed - Faster Trials)\n",
        "def objective_xgb(trial, X_data, y_data):\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'eta': trial.suggest_float('eta', 0.01, 0.2, log=True), # learning_rate, adjusted for fewer estimators\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12), # Kept original range\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
        "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
        "        'n_estimators': 300,  # << PRIMARY CHANGE FOR SPEED PER TRIAL\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'n_jobs': 2\n",
        "    }\n",
        "    model = Pipeline([\n",
        "        ('prep', preprocessor),\n",
        "        ('xgb', XGBRegressor(**params, tree_method='hist'))\n",
        "    ])\n",
        "    cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE) # Kept original n_splits\n",
        "    scores = cross_val_score(model, X_data, y_data, cv=cv,\n",
        "                             scoring='neg_root_mean_squared_error', n_jobs=2)\n",
        "    return -np.mean(scores)\n",
        "\n",
        "print(\"Optimizing XGBoost (Minimally changed: fewer estimators per HPO trial)...\")\n",
        "study_xgb = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
        "study_xgb.optimize(lambda trial: objective_xgb(trial, X, y), n_trials=40, n_jobs=1) # Kept original n_trials\n",
        "best_xgb_params = study_xgb.best_params\n",
        "print(\"Best XGBoost CV RMSE (from faster HPO - expect this RMSE to be higher):\", study_xgb.best_value)\n",
        "print(\"Best XGBoost parameters (from faster HPO):\", best_xgb_params)\n",
        "\n",
        "# Optional: Save Best XGBoost Params to JSON\n",
        "import json\n",
        "filename_xgb_params = \"best_xgboost_hpo_params_fast_trials.json\"\n",
        "try:\n",
        "    with open(filename_xgb_params, 'w') as f:\n",
        "        json.dump(best_xgb_params, f, indent=4)\n",
        "    print(f\"Successfully saved Best XGBoost parameters (fast trials) to {filename_xgb_params}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving XGBoost parameters to JSON: {e}\")\n",
        "\n",
        "# In Cell 11 for xgb_final:\n",
        "# final_xgb_params = best_xgb_params.copy()\n",
        "# final_xgb_params['n_estimators'] = 1500 # Or 2000, your original target for final model\n",
        "# # The 'eta' found by Optuna will be used.\n",
        "# final_xgb_params.update({ ... other essential final params ...})\n",
        "# xgb_final = Pipeline(...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyLxV2OmA-tV",
        "outputId": "301f379c-7b74-4beb-929f-5442b0d1e4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 12:48:49,077] A new study created in memory with name: no-name-e4f4506d-036a-4c81-be5d-c89c8393c3fe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing XGBoost (Minimally changed: fewer estimators per HPO trial)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 12:49:22,773] Trial 0 finished with value: 0.104960582461162 and parameters: {'eta': 0.030710573677773714, 'max_depth': 12, 'subsample': 0.8659969709057025, 'colsample_bytree': 0.7993292420985183, 'min_child_weight': 4, 'gamma': 1.7699302940633311e-07, 'lambda': 3.3323645788192616e-08, 'alpha': 0.6245760287469893}. Best is trial 0 with value: 0.104960582461162.\n",
            "[I 2025-06-07 12:49:33,864] Trial 1 finished with value: 0.10698863244395276 and parameters: {'eta': 0.06054365855469246, 'max_depth': 10, 'subsample': 0.5102922471479012, 'colsample_bytree': 0.9849549260809971, 'min_child_weight': 17, 'gamma': 4.997040685255803e-07, 'lambda': 4.329370014459266e-07, 'alpha': 4.4734294104626844e-07}. Best is trial 0 with value: 0.104960582461162.\n",
            "[I 2025-06-07 12:49:41,625] Trial 2 finished with value: 0.10398293261859329 and parameters: {'eta': 0.024878734419814436, 'max_depth': 8, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021, 'min_child_weight': 13, 'gamma': 1.3060231803531604e-07, 'lambda': 4.258943089524393e-06, 'alpha': 1.9826980964985924e-05}. Best is trial 2 with value: 0.10398293261859329.\n",
            "[I 2025-06-07 12:49:53,151] Trial 3 finished with value: 0.10542759096644365 and parameters: {'eta': 0.03920673972242137, 'max_depth': 10, 'subsample': 0.5998368910791798, 'colsample_bytree': 0.7571172192068059, 'min_child_weight': 12, 'gamma': 2.3528990899815284e-08, 'lambda': 0.0029369981104377003, 'alpha': 3.425445902633376e-07}. Best is trial 2 with value: 0.10398293261859329.\n",
            "[I 2025-06-07 12:50:37,847] Trial 4 finished with value: 0.10555292650462152 and parameters: {'eta': 0.012151617026673379, 'max_depth': 12, 'subsample': 0.9828160165372797, 'colsample_bytree': 0.9041986740582306, 'min_child_weight': 7, 'gamma': 6.044730070370796e-08, 'lambda': 0.014391207615728067, 'alpha': 9.148975058772307e-05}. Best is trial 2 with value: 0.10398293261859329.\n",
            "[I 2025-06-07 12:50:45,234] Trial 5 finished with value: 0.10355505361916686 and parameters: {'eta': 0.014413697528610409, 'max_depth': 7, 'subsample': 0.5171942605576092, 'colsample_bytree': 0.954660201039391, 'min_child_weight': 6, 'gamma': 0.0019960815242513743, 'lambda': 6.388511557344611e-06, 'alpha': 0.0004793052550782129}. Best is trial 5 with value: 0.10355505361916686.\n",
            "[I 2025-06-07 12:50:46,749] Trial 6 finished with value: 0.1034896921169401 and parameters: {'eta': 0.05143828405076928, 'max_depth': 4, 'subsample': 0.9847923138822793, 'colsample_bytree': 0.8875664116805573, 'min_child_weight': 19, 'gamma': 0.14408501080722544, 'lambda': 0.002404915432737351, 'alpha': 1.9809253750493907}. Best is trial 6 with value: 0.1034896921169401.\n",
            "[I 2025-06-07 12:50:49,823] Trial 7 finished with value: 0.1037968142610975 and parameters: {'eta': 0.01303561122512888, 'max_depth': 4, 'subsample': 0.522613644455269, 'colsample_bytree': 0.6626651653816322, 'min_child_weight': 8, 'gamma': 1.481809088646707e-06, 'lambda': 0.28749982347407854, 'alpha': 1.6247252885719427e-05}. Best is trial 6 with value: 0.1034896921169401.\n",
            "[I 2025-06-07 12:50:51,488] Trial 8 finished with value: 0.10535273594379566 and parameters: {'eta': 0.023200867504756827, 'max_depth': 8, 'subsample': 0.5704621124873813, 'colsample_bytree': 0.9010984903770198, 'min_child_weight': 2, 'gamma': 0.7854083114461319, 'lambda': 0.08916674715636537, 'alpha': 6.143857495033091e-07}. Best is trial 6 with value: 0.1034896921169401.\n",
            "[I 2025-06-07 12:51:15,171] Trial 9 finished with value: 0.10424217675040777 and parameters: {'eta': 0.010166803740022877, 'max_depth': 11, 'subsample': 0.8534286719238086, 'colsample_bytree': 0.8645035840204937, 'min_child_weight': 16, 'gamma': 3.911625006683821e-08, 'lambda': 1.683416412018213e-05, 'alpha': 1.1036250149900698e-07}. Best is trial 6 with value: 0.1034896921169401.\n",
            "[I 2025-06-07 12:51:16,318] Trial 10 finished with value: 0.10446219002556059 and parameters: {'eta': 0.16917635629157515, 'max_depth': 3, 'subsample': 0.9847685553939328, 'colsample_bytree': 0.5089809378074097, 'min_child_weight': 20, 'gamma': 0.18252332105365568, 'lambda': 4.344469108550396, 'alpha': 6.178893500921428}. Best is trial 6 with value: 0.1034896921169401.\n",
            "[I 2025-06-07 12:51:19,600] Trial 11 finished with value: 0.10467566497397855 and parameters: {'eta': 0.06916991586734614, 'max_depth': 5, 'subsample': 0.6779595353168644, 'colsample_bytree': 0.9729048599868566, 'min_child_weight': 8, 'gamma': 0.005641460940688057, 'lambda': 0.000179649519485956, 'alpha': 0.03417577311376878}. Best is trial 6 with value: 0.1034896921169401.\n",
            "[I 2025-06-07 12:51:24,406] Trial 12 finished with value: 0.10652186726647388 and parameters: {'eta': 0.0998053416483338, 'max_depth': 6, 'subsample': 0.8255046671084629, 'colsample_bytree': 0.8382876013411128, 'min_child_weight': 4, 'gamma': 0.001853649705949485, 'lambda': 0.0002709187673312064, 'alpha': 0.0074839487022762274}. Best is trial 6 with value: 0.1034896921169401.\n",
            "[I 2025-06-07 12:51:29,413] Trial 13 finished with value: 0.10322556036849644 and parameters: {'eta': 0.01846775816443898, 'max_depth': 6, 'subsample': 0.7846689081265132, 'colsample_bytree': 0.9980082658737177, 'min_child_weight': 20, 'gamma': 4.491039276445898e-05, 'lambda': 2.1121685904955737e-05, 'alpha': 0.002400553975134393}. Best is trial 13 with value: 0.10322556036849644.\n",
            "[I 2025-06-07 12:51:31,344] Trial 14 finished with value: 0.10324931361934586 and parameters: {'eta': 0.019602282595315667, 'max_depth': 3, 'subsample': 0.9219900508555974, 'colsample_bytree': 0.9994759208204097, 'min_child_weight': 20, 'gamma': 6.287951645794466e-06, 'lambda': 0.00309749836874157, 'alpha': 0.09258636304913416}. Best is trial 13 with value: 0.10322556036849644.\n",
            "[I 2025-06-07 12:51:33,320] Trial 15 finished with value: 0.10318128660731789 and parameters: {'eta': 0.01884282208724622, 'max_depth': 3, 'subsample': 0.7853246564686904, 'colsample_bytree': 0.9974098384114692, 'min_child_weight': 15, 'gamma': 1.2011377451644636e-05, 'lambda': 7.672083453229088e-05, 'alpha': 0.033617159174804394}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:51:38,181] Trial 16 finished with value: 0.10342402025403168 and parameters: {'eta': 0.018238076468563704, 'max_depth': 6, 'subsample': 0.7921656945806025, 'colsample_bytree': 0.6715548428380943, 'min_child_weight': 16, 'gamma': 3.870153185169783e-05, 'lambda': 4.151172654990996e-07, 'alpha': 0.001993237885140234}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:51:41,480] Trial 17 finished with value: 0.10329408249598562 and parameters: {'eta': 0.03459516358459857, 'max_depth': 5, 'subsample': 0.7590324446167176, 'colsample_bytree': 0.9336501321142189, 'min_child_weight': 14, 'gamma': 0.00015082523619067042, 'lambda': 5.787099912698904e-05, 'alpha': 0.14524112213119972}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:51:47,184] Trial 18 finished with value: 0.10385999081050461 and parameters: {'eta': 0.015374141448814691, 'max_depth': 7, 'subsample': 0.662500525099712, 'colsample_bytree': 0.5354088860925215, 'min_child_weight': 18, 'gamma': 9.22072923926949e-05, 'lambda': 2.1219899323605756e-08, 'alpha': 0.008348370397086198}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:51:58,852] Trial 19 finished with value: 0.10446084926739121 and parameters: {'eta': 0.026019391380347617, 'max_depth': 9, 'subsample': 0.901876155039429, 'colsample_bytree': 0.8198321304454206, 'min_child_weight': 11, 'gamma': 6.206285337375755e-06, 'lambda': 3.984821270918685e-07, 'alpha': 0.00042472564292351313}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:01,292] Trial 20 finished with value: 0.1040577100582197 and parameters: {'eta': 0.09003320293419312, 'max_depth': 4, 'subsample': 0.7489871979791521, 'colsample_bytree': 0.728032836923177, 'min_child_weight': 15, 'gamma': 0.0004875309725900002, 'lambda': 1.50331165614839e-06, 'alpha': 6.373268555949988e-06}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:03,480] Trial 21 finished with value: 0.10327509936331188 and parameters: {'eta': 0.018835844397009527, 'max_depth': 3, 'subsample': 0.9090660125942205, 'colsample_bytree': 0.9986636612415092, 'min_child_weight': 20, 'gamma': 8.525831122089978e-06, 'lambda': 0.001790365417283956, 'alpha': 0.13764985435921728}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:05,403] Trial 22 finished with value: 0.10321446138590909 and parameters: {'eta': 0.02036544588270477, 'max_depth': 3, 'subsample': 0.9328586774703974, 'colsample_bytree': 0.934509695431901, 'min_child_weight': 18, 'gamma': 1.0771395709556367e-05, 'lambda': 4.675016135122935e-05, 'alpha': 0.035074256884790295}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:08,842] Trial 23 finished with value: 0.10324827625351556 and parameters: {'eta': 0.029820243659269486, 'max_depth': 5, 'subsample': 0.7965042392512289, 'colsample_bytree': 0.9393135032915165, 'min_child_weight': 18, 'gamma': 2.1215052463824673e-05, 'lambda': 3.4761658643264604e-05, 'alpha': 0.0047090634643883866}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:13,949] Trial 24 finished with value: 0.1032418490581872 and parameters: {'eta': 0.020279369763653826, 'max_depth': 6, 'subsample': 0.6734894147530057, 'colsample_bytree': 0.9482480136731888, 'min_child_weight': 17, 'gamma': 1.788237944663216e-06, 'lambda': 9.997769986593786e-05, 'alpha': 0.04195786727793909}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:16,654] Trial 25 finished with value: 0.10384989593580578 and parameters: {'eta': 0.010563910643501649, 'max_depth': 4, 'subsample': 0.9396371247577118, 'colsample_bytree': 0.9127890176168874, 'min_child_weight': 14, 'gamma': 0.00022208435626777784, 'lambda': 0.0008849299239384554, 'alpha': 1.4984260363555144e-08}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:18,588] Trial 26 finished with value: 0.10346371060092592 and parameters: {'eta': 0.016169533342034383, 'max_depth': 3, 'subsample': 0.8379951565025081, 'colsample_bytree': 0.8623924420935414, 'min_child_weight': 10, 'gamma': 1.4401743652922463e-06, 'lambda': 1.0615957086632574e-05, 'alpha': 0.0012457452192464827}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:22,649] Trial 27 finished with value: 0.10344661511652839 and parameters: {'eta': 0.040396304658211944, 'max_depth': 5, 'subsample': 0.7186108907232278, 'colsample_bytree': 0.9625632338704708, 'min_child_weight': 18, 'gamma': 3.366857273023969e-05, 'lambda': 1.653973996100687e-06, 'alpha': 0.48646147990777183}. Best is trial 15 with value: 0.10318128660731789.\n",
            "[I 2025-06-07 12:52:25,090] Trial 28 finished with value: 0.10304330718753012 and parameters: {'eta': 0.02335750931072813, 'max_depth': 4, 'subsample': 0.881537529800556, 'colsample_bytree': 0.7969365482750832, 'min_child_weight': 15, 'gamma': 0.012604526291546738, 'lambda': 0.013751395138753668, 'alpha': 0.020204285944243935}. Best is trial 28 with value: 0.10304330718753012.\n",
            "[I 2025-06-07 12:52:26,954] Trial 29 finished with value: 0.10307162114681645 and parameters: {'eta': 0.0293904200520091, 'max_depth': 3, 'subsample': 0.859606806308948, 'colsample_bytree': 0.7547957914297356, 'min_child_weight': 15, 'gamma': 0.009344108910695322, 'lambda': 0.028445946774976128, 'alpha': 1.0559603429974158}. Best is trial 28 with value: 0.10304330718753012.\n",
            "[I 2025-06-07 12:52:29,289] Trial 30 finished with value: 0.10303624572124237 and parameters: {'eta': 0.03265838970310793, 'max_depth': 4, 'subsample': 0.8853021085905313, 'colsample_bytree': 0.7440351527384239, 'min_child_weight': 10, 'gamma': 0.02040347641009306, 'lambda': 0.026134885240669477, 'alpha': 1.045090080200313}. Best is trial 30 with value: 0.10303624572124237.\n",
            "[I 2025-06-07 12:52:31,701] Trial 31 finished with value: 0.10301383586503032 and parameters: {'eta': 0.030881651323450904, 'max_depth': 4, 'subsample': 0.8788239775227437, 'colsample_bytree': 0.7807231174177514, 'min_child_weight': 10, 'gamma': 0.020042881084584397, 'lambda': 0.02573487256683641, 'alpha': 0.7541782189867495}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:34,420] Trial 32 finished with value: 0.10383194527975403 and parameters: {'eta': 0.031158392397840753, 'max_depth': 4, 'subsample': 0.878987434896326, 'colsample_bytree': 0.7771970010054017, 'min_child_weight': 10, 'gamma': 0.019388440212796513, 'lambda': 0.05553144430982789, 'alpha': 9.445489061616154}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:36,316] Trial 33 finished with value: 0.10311423868399963 and parameters: {'eta': 0.0514441522490444, 'max_depth': 4, 'subsample': 0.8860918037761012, 'colsample_bytree': 0.7079457683431398, 'min_child_weight': 12, 'gamma': 0.027999300674945205, 'lambda': 1.27317276924497, 'alpha': 0.9355392516235405}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:39,204] Trial 34 finished with value: 0.10320199793558835 and parameters: {'eta': 0.027907715684637454, 'max_depth': 5, 'subsample': 0.9528023905240883, 'colsample_bytree': 0.7937628490115393, 'min_child_weight': 9, 'gamma': 0.029915750574895424, 'lambda': 0.013257004303715283, 'alpha': 0.4641304784018423}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:41,585] Trial 35 finished with value: 0.1031519192714303 and parameters: {'eta': 0.037390852110269046, 'max_depth': 4, 'subsample': 0.8638289262483126, 'colsample_bytree': 0.7510230289488432, 'min_child_weight': 12, 'gamma': 0.005473280881319025, 'lambda': 0.014302082626478328, 'alpha': 2.934629479830138}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:43,227] Trial 36 finished with value: 0.10350625229119219 and parameters: {'eta': 0.04651262939770374, 'max_depth': 5, 'subsample': 0.8209540884744877, 'colsample_bytree': 0.5961070245308178, 'min_child_weight': 11, 'gamma': 0.14535219687328593, 'lambda': 0.206548940207663, 'alpha': 1.1686981258194837}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:49,997] Trial 37 finished with value: 0.10372726445640587 and parameters: {'eta': 0.02425304476931026, 'max_depth': 7, 'subsample': 0.8577626609921719, 'colsample_bytree': 0.7028584500912429, 'min_child_weight': 6, 'gamma': 0.007839922521176674, 'lambda': 0.7664476560945703, 'alpha': 0.24106380034632582}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:51,799] Trial 38 finished with value: 0.10316931231721971 and parameters: {'eta': 0.03195095839368401, 'max_depth': 3, 'subsample': 0.9659568557014001, 'colsample_bytree': 0.7747021830049129, 'min_child_weight': 14, 'gamma': 0.0006834355836671778, 'lambda': 0.028042127644139367, 'alpha': 2.6820351025033626}. Best is trial 31 with value: 0.10301383586503032.\n",
            "[I 2025-06-07 12:52:53,138] Trial 39 finished with value: 0.10401499362712538 and parameters: {'eta': 0.0673843771247438, 'max_depth': 4, 'subsample': 0.8980231312895571, 'colsample_bytree': 0.8126664025684257, 'min_child_weight': 13, 'gamma': 0.42045520170621414, 'lambda': 0.005226170588984455, 'alpha': 0.34475540418187317}. Best is trial 31 with value: 0.10301383586503032.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost CV RMSE (from faster HPO - expect this RMSE to be higher): 0.10301383586503032\n",
            "Best XGBoost parameters (from faster HPO): {'eta': 0.030881651323450904, 'max_depth': 4, 'subsample': 0.8788239775227437, 'colsample_bytree': 0.7807231174177514, 'min_child_weight': 10, 'gamma': 0.020042881084584397, 'lambda': 0.02573487256683641, 'alpha': 0.7541782189867495}\n",
            "Successfully saved Best XGBoost parameters (fast trials) to best_xgboost_hpo_params_fast_trials.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Final Model Definitions (Base Learners)\n",
        "import json # Ensure json is imported for loading\n",
        "\n",
        "print(\"Building final model pipelines by loading HPO parameters from JSON...\")\n",
        "\n",
        "# --- Load LightGBM Parameters ---\n",
        "try:\n",
        "    with open(\"/content/best_lgb_params.json\", 'r') as f:\n",
        "        best_lgb_params = json.load(f)\n",
        "    print(\"Successfully loaded best_lgb_params from /content/best_lgb_params.json\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: /content/best_lgb_params.json not found! Using empty dict (will likely fail or use defaults).\")\n",
        "    best_lgb_params = {} # Fallback to prevent immediate error, but model will be default\n",
        "except json.JSONDecodeError:\n",
        "    print(\"ERROR: Could not decode JSON from /content/best_lgb_params.json! Using empty dict.\")\n",
        "    best_lgb_params = {}\n",
        "\n",
        "# --- Load CatBoost Parameters ---\n",
        "try:\n",
        "    with open(\"/content/best_catboost_hpo_params.json\", 'r') as f:\n",
        "        best_cat_params = json.load(f)\n",
        "    print(\"Successfully loaded best_cat_params from /content/best_catboost_hpo_params.json\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: /content/best_catboost_hpo_params.json not found! Using empty dict.\")\n",
        "    best_cat_params = {}\n",
        "except json.JSONDecodeError:\n",
        "    print(\"ERROR: Could not decode JSON from /content/best_catboost_hpo_params.json! Using empty dict.\")\n",
        "    best_cat_params = {}\n",
        "\n",
        "# --- Load XGBoost Parameters ---\n",
        "try:\n",
        "    with open(\"/content/best_xgboost_hpo_params_fast_trials.json\", 'r') as f:\n",
        "        best_xgb_params = json.load(f)\n",
        "    print(\"Successfully loaded best_xgb_params from /content/best_xgboost_hpo_params_fast_trials.json\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: /content/best_xgboost_hpo_params_fast_trials.json not found! Using empty dict.\")\n",
        "    best_xgb_params = {}\n",
        "except json.JSONDecodeError:\n",
        "    print(\"ERROR: Could not decode JSON from /content/best_xgboost_hpo_params_fast_trials.json! Using empty dict.\")\n",
        "    best_xgb_params = {}\n",
        "\n",
        "\n",
        "# Ensure 'n_estimators' or 'iterations' are set for final training, and other essential params\n",
        "\n",
        "# --- Define LightGBM Final Pipeline ---\n",
        "if best_lgb_params: # Proceed only if params were loaded\n",
        "    final_lgb_params = best_lgb_params.copy()\n",
        "    final_lgb_params.update({\n",
        "        'n_estimators': 2500, # Increased for final model\n",
        "        'random_state': RANDOM_STATE,\n",
        "        'verbosity': -1,\n",
        "        # Ensure objective and metric are present if not in HPO params, or override if needed\n",
        "        'objective': final_lgb_params.get('objective', 'regression_l1'),\n",
        "        'metric': final_lgb_params.get('metric', 'rmse')\n",
        "    })\n",
        "    lgb_final = Pipeline([\n",
        "        ('prep', preprocessor),\n",
        "        ('lgbm', LGBMRegressor(**final_lgb_params))\n",
        "    ])\n",
        "    print(\"LightGBM final pipeline defined.\")\n",
        "else:\n",
        "    print(\"Skipping LightGBM final pipeline definition due to missing parameters.\")\n",
        "    lgb_final = None # Or a default model pipeline if you prefer\n",
        "\n",
        "# --- Define CatBoost Final Pipeline ---\n",
        "if best_cat_params: # Proceed only if params were loaded\n",
        "    final_cat_params = best_cat_params.copy()\n",
        "    # CRITICAL: Increase 'iterations' for the final model\n",
        "    # The 'iterations' from HPO (e.g., 300) is specific to faster HPO.\n",
        "    final_cat_params['iterations'] = 2500 # Increased for final model\n",
        "\n",
        "    final_cat_params.update({\n",
        "        'random_seed': RANDOM_STATE,\n",
        "        'verbose': 0, # Suppress output during stacking\n",
        "        # Ensure loss_function is present if not in HPO params\n",
        "        'loss_function': final_cat_params.get('loss_function', 'RMSE'),\n",
        "        'thread_count': -1 # Use all available threads for final model training\n",
        "    })\n",
        "    cat_final = Pipeline([\n",
        "        ('prep', preprocessor),\n",
        "        ('cat', CatBoostRegressor(**final_cat_params))\n",
        "    ])\n",
        "    print(\"CatBoost final pipeline defined.\")\n",
        "else:\n",
        "    print(\"Skipping CatBoost final pipeline definition due to missing parameters.\")\n",
        "    cat_final = None\n",
        "\n",
        "# --- Define XGBoost Final Pipeline ---\n",
        "if best_xgb_params: # Proceed only if params were loaded\n",
        "    final_xgb_params = best_xgb_params.copy()\n",
        "    # CRITICAL: Increase 'n_estimators' for the final model\n",
        "    # The 'n_estimators' from HPO (e.g., 300) is specific to faster HPO.\n",
        "    final_xgb_params['n_estimators'] = 2500 # Increased for final model\n",
        "\n",
        "    # The 'eta' (learning rate) found by Optuna during HPO will be used.\n",
        "    # It was optimized for fewer estimators, but often works well or is a good start.\n",
        "    final_xgb_params.update({\n",
        "        'random_state': RANDOM_STATE,\n",
        "        # Ensure objective and eval_metric are present if not in HPO params\n",
        "        'objective': final_xgb_params.get('objective', 'reg:squarederror'),\n",
        "        'eval_metric': final_xgb_params.get('eval_metric', 'rmse'),\n",
        "        'n_jobs': -1 # Use all available threads for final training\n",
        "    })\n",
        "    xgb_final = Pipeline([\n",
        "        ('prep', preprocessor),\n",
        "        ('xgb', XGBRegressor(**final_xgb_params, tree_method='hist')) # Keep tree_method='hist'\n",
        "    ])\n",
        "    print(\"XGBoost final pipeline defined.\")\n",
        "else:\n",
        "    print(\"Skipping XGBoost final pipeline definition due to missing parameters.\")\n",
        "    xgb_final = None\n",
        "\n",
        "print(\"Base learner pipelines defined (or skipped if params were missing).\")\n",
        "\n",
        "# The rest of your Cell 11 (StackingRegressor definition) would follow.\n",
        "# You'll need to handle cases where lgb_final, cat_final, or xgb_final might be None\n",
        "# if their parameters couldn't be loaded, e.g., by excluding them from the stack.\n",
        "# For simplicity here, I am assuming they will be loaded. If not, the stacking part needs adjustment."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5C4zYwnBA-9",
        "outputId": "b10852e1-b7b6-46f7-928f-17785fec6c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building final model pipelines by loading HPO parameters from JSON...\n",
            "Successfully loaded best_lgb_params from /content/best_lgb_params.json\n",
            "Successfully loaded best_cat_params from /content/best_catboost_hpo_params.json\n",
            "Successfully loaded best_xgb_params from /content/best_xgboost_hpo_params_fast_trials.json\n",
            "LightGBM final pipeline defined.\n",
            "CatBoost final pipeline defined.\n",
            "XGBoost final pipeline defined.\n",
            "Base learner pipelines defined (or skipped if params were missing).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Stacking Regressor Definition\n",
        "\n",
        "# Meta-learner for stacking\n",
        "meta_learner = LGBMRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.03, # Slightly lower LR for meta-learner\n",
        "    num_leaves=20,     # Simpler meta-learner\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        "    verbosity=-1,\n",
        "    colsample_bytree=0.7, # Add some regularization\n",
        "    subsample=0.7\n",
        ")\n",
        "\n",
        "stack = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('lgbm', lgb_final),\n",
        "        ('cat', cat_final),\n",
        "        ('xgb', xgb_final)\n",
        "    ],\n",
        "    final_estimator=meta_learner,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE + 1), # Use a different seed for stacking CV\n",
        "    n_jobs=-1, # Parallelize stacking model fitting\n",
        "    passthrough=False # Features are preprocessed by base learners, no need to pass raw to meta\n",
        ")\n",
        "print(\"Stacking regressor defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9KKcsQNBEnI",
        "outputId": "4f3d6343-1211-4172-f09b-74e94b8374e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking regressor defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Final Model Training\n",
        "print(\"Training final stacked model... This may take a while.\")\n",
        "total_model = stack.fit(X, y)\n",
        "print(\"Final model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Knmvt_-BGi1",
        "outputId": "c339e196-ad4d-4461-e343-951cf528dca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final stacked model... This may take a while.\n",
            "Final model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Prediction and Clipping\n",
        "print(\"Making predictions on the test set...\")\n",
        "preds = total_model.predict(X_test)\n",
        "\n",
        "# Clipping predictions to the observed range in the training target\n",
        "y_min_train = y.min()\n",
        "y_max_train = y.max()\n",
        "print(f\"Clipping predictions to the training range: [{y_min_train:.4f}, {y_max_train:.4f}]\")\n",
        "preds_clipped = np.clip(preds, y_min_train, y_max_train)\n",
        "\n",
        "# Check if clipping had an effect\n",
        "if not np.allclose(preds, preds_clipped):\n",
        "    print(f\"Clipping changed {np.sum(preds != preds_clipped)} prediction values.\")\n",
        "    print(f\"Min pred before clip: {preds.min():.4f}, Min pred after clip: {preds_clipped.min():.4f}\")\n",
        "    print(f\"Max pred before clip: {preds.max():.4f}, Max pred after clip: {preds_clipped.max():.4f}\")\n",
        "else:\n",
        "    print(\"Clipping did not significantly change prediction values.\")\n",
        "print(\"Predictions made and clipped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Vd4qX4BIwv",
        "outputId": "0359da68-242c-440e-be8e-d3eb41b620c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making predictions on the test set...\n",
            "Clipping predictions to the training range: [0.0000, 0.9871]\n",
            "Clipping did not significantly change prediction values.\n",
            "Predictions made and clipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Submission File Creation\n",
        "submission = pd.DataFrame({'id': test_ids, 'efficiency': preds_clipped})\n",
        "submission_filename = 'submission_stacked_enhanced.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "print(f\"Saved submission file: {submission_filename} (Shape: {submission.shape})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqc8MKIhBK6H",
        "outputId": "6d1752ce-fa96-41d5-ada3-b5db03a1d8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission file: submission_stacked_enhanced.csv (Shape: (12000, 2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Optuna Summaries and Finish Message\n",
        "print(\"\\n--- Optuna Study Summaries ---\")\n",
        "print(f\"\\nLGBM Best CV RMSE: {study_lgb.best_value:.5f}\")\n",
        "print(\"LGBM Best Params:\", study_lgb.best_params)\n",
        "print(f\"\\nCatBoost Best CV RMSE: {study_cat.best_value:.5f}\")\n",
        "print(\"CatBoost Best Params:\", study_cat.best_params)\n",
        "print(f\"\\nXGBoost Best CV RMSE: {study_xgb.best_value:.5f}\")\n",
        "print(\"XGBoost Best Params:\", study_xgb.best_params)\n",
        "\n",
        "print(\"\\nCode execution finished.\")\n",
        "\n",
        "# Optional: Visualize Optuna studies if desired\n",
        "# import optuna.visualization as vis\n",
        "# vis.plot_optimization_history(study_lgb).show()\n",
        "# vis.plot_param_importances(study_lgb).show()\n",
        "# (repeat for study_cat and study_xgb)"
      ],
      "metadata": {
        "id": "iXNAbkeSBPvy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}